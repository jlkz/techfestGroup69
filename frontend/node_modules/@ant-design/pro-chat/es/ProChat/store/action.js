import _objectSpread from "@babel/runtime/helpers/esm/objectSpread2";
import _regeneratorRuntime from "@babel/runtime/helpers/esm/regeneratorRuntime";
import _asyncToGenerator from "@babel/runtime/helpers/esm/asyncToGenerator";
import { merge, template } from 'lodash-es';
import { LOADING_FLAT } from "../const/message";
import { fetchSSE } from "../utils/fetch";
import { isFunctionMessage } from "../utils/message";
import { setNamespace } from "../utils/storeDebug";
import { nanoid } from "../utils/uuid";
import { initialModelConfig } from "./initialState";
import { getSlicedMessagesWithConfig } from "../utils/message";
import { messagesReducer } from "./reducers/message";
import { chatSelectors } from "./selectors";
var t = setNamespace('chat/message');

/**
 * 聊天操作
 */

export var chatAction = function chatAction(set, get) {
  return {
    clearMessage: function () {
      var _clearMessage = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {
        var _get, dispatchMessage, onResetMessage;
        return _regeneratorRuntime().wrap(function _callee$(_context) {
          while (1) switch (_context.prev = _context.next) {
            case 0:
              _get = get(), dispatchMessage = _get.dispatchMessage, onResetMessage = _get.onResetMessage; // 重置消息，清空聊天记录，等待 onResetMessage 完成后再清空
              if (!onResetMessage) {
                _context.next = 4;
                break;
              }
              _context.next = 4;
              return onResetMessage();
            case 4:
              dispatchMessage({
                type: 'resetMessages'
              });

              // TODO: need callback after reset
            case 5:
            case "end":
              return _context.stop();
          }
        }, _callee);
      }));
      function clearMessage() {
        return _clearMessage.apply(this, arguments);
      }
      return clearMessage;
    }(),
    deleteMessage: function deleteMessage(id) {
      get().dispatchMessage({
        id: id,
        type: 'deleteMessage'
      });
    },
    dispatchMessage: function dispatchMessage(payload) {
      var _get2 = get(),
        chats = _get2.chats,
        onChatsChange = _get2.onChatsChange;
      var nextChats = messagesReducer(chats, payload);
      set({
        chats: nextChats
      }, false, t('dispatchMessage'));
      onChatsChange === null || onChatsChange === void 0 || onChatsChange(nextChats);
    },
    generateMessage: function () {
      var _generateMessage = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(messages, assistantId) {
        var _get3, dispatchMessage, toggleChatLoading, config, defaultModelFetcher, abortController, slicedMessages, compilerMessages, postMessages, fetcher, output, isFunctionCall, timeId;
        return _regeneratorRuntime().wrap(function _callee2$(_context2) {
          while (1) switch (_context2.prev = _context2.next) {
            case 0:
              _get3 = get(), dispatchMessage = _get3.dispatchMessage, toggleChatLoading = _get3.toggleChatLoading, config = _get3.config, defaultModelFetcher = _get3.defaultModelFetcher;
              abortController = toggleChatLoading(true, assistantId, t('generateMessage(start)', {
                assistantId: assistantId,
                messages: messages
              })); // ========================== //
              //   对 messages 做统一预处理    //
              // ========================== //
              // 1. 按参数设定截断长度
              slicedMessages = getSlicedMessagesWithConfig(messages, config); // 2. 替换 inputMessage 模板
              compilerMessages = function compilerMessages(slicedMessages) {
                var compiler = template(config.inputTemplate, {
                  interpolate: /{{([\S\s]+?)}}/g
                });
                return slicedMessages.map(function (m) {
                  if (m.role === 'user') {
                    try {
                      return _objectSpread(_objectSpread({}, m), {}, {
                        content: compiler({
                          text: m.content
                        })
                      });
                    } catch (error) {
                      console.error(error);
                      return m;
                    }
                  }
                  return m;
                });
              };
              postMessages = !config.inputTemplate ? slicedMessages : compilerMessages(slicedMessages); // 3. 添加 systemRole
              if (config.systemRole) {
                postMessages.unshift({
                  content: config.systemRole,
                  role: 'system'
                });
              }
              fetcher = function fetcher() {
                return defaultModelFetcher(_objectSpread({
                  messages: postMessages,
                  model: config.model
                }, config.params), {
                  signal: abortController === null || abortController === void 0 ? void 0 : abortController.signal
                });
              };
              output = '';
              isFunctionCall = false;
              timeId = 0;
              _context2.next = 12;
              return fetchSSE(fetcher, {
                onErrorHandle: function onErrorHandle(error) {
                  dispatchMessage({
                    id: assistantId,
                    key: 'error',
                    type: 'updateMessage',
                    value: error
                  });
                },
                onMessageHandle: function onMessageHandle(text) {
                  output += text;

                  // 如果存在上一个定时器，那么清除
                  if (timeId) clearTimeout(timeId);

                  // 使用定时器来监听性能，保证出入的时候不会太卡顿
                  timeId = (window.requestIdleCallback || window.setTimeout)(function () {
                    dispatchMessage({
                      id: assistantId,
                      key: 'content',
                      type: 'updateMessage',
                      value: output
                    });
                  });

                  // TODO: need a function call judge callback
                  // 如果是 function call
                  if (isFunctionMessage(output)) {
                    isFunctionCall = true;
                  }
                }
              });
            case 12:
              (window.requestIdleCallback || window.setTimeout)(function () {
                toggleChatLoading(false, undefined, t('generateMessage(end)'));
              });
              return _context2.abrupt("return", {
                isFunctionCall: isFunctionCall
              });
            case 14:
            case "end":
              return _context2.stop();
          }
        }, _callee2);
      }));
      function generateMessage(_x, _x2) {
        return _generateMessage.apply(this, arguments);
      }
      return generateMessage;
    }(),
    realFetchAIResponse: function () {
      var _realFetchAIResponse = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(messages, userMessageId) {
        var _get4, dispatchMessage, generateMessage, config, getMessageId, mid;
        return _regeneratorRuntime().wrap(function _callee3$(_context3) {
          while (1) switch (_context3.prev = _context3.next) {
            case 0:
              _get4 = get(), dispatchMessage = _get4.dispatchMessage, generateMessage = _get4.generateMessage, config = _get4.config, getMessageId = _get4.getMessageId; // 添加一个空的信息用于放置 ai 响应，注意顺序不能反
              // 因为如果顺序反了，messages 中将包含新增的 ai message
              _context3.next = 3;
              return getMessageId(messages, userMessageId);
            case 3:
              mid = _context3.sent;
              dispatchMessage({
                id: mid,
                message: LOADING_FLAT,
                parentId: userMessageId,
                role: 'assistant',
                type: 'addMessage'
              });

              // TODO: need a callback before generate message

              // 为模型添加 fromModel 的额外信息
              // TODO: 此处需要model 信息
              dispatchMessage({
                id: mid,
                key: 'fromModel',
                type: 'updateMessageExtra',
                value: config.model
              });

              // 生成 ai message
              _context3.next = 8;
              return generateMessage(messages, mid);
            case 8:
            case "end":
              return _context3.stop();
          }
        }, _callee3);
      }));
      function realFetchAIResponse(_x3, _x4) {
        return _realFetchAIResponse.apply(this, arguments);
      }
      return realFetchAIResponse;
    }(),
    resendMessage: function () {
      var _resendMessage = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(messageId) {
        var chats, currentIndex, currentMessage, contextMessages, userId, userIndex, _get5, realFetchAIResponse, latestMsg;
        return _regeneratorRuntime().wrap(function _callee4$(_context4) {
          while (1) switch (_context4.prev = _context4.next) {
            case 0:
              // 1. 构造所有相关的历史记录
              chats = chatSelectors.currentChats(get());
              currentIndex = chats.findIndex(function (c) {
                return c.id === messageId;
              });
              if (!(currentIndex < 0)) {
                _context4.next = 4;
                break;
              }
              return _context4.abrupt("return");
            case 4:
              currentMessage = chats[currentIndex];
              contextMessages = [];
              _context4.t0 = currentMessage.role;
              _context4.next = _context4.t0 === 'function' ? 9 : _context4.t0 === 'user' ? 9 : _context4.t0 === 'assistant' ? 11 : 15;
              break;
            case 9:
              contextMessages = chats.slice(0, currentIndex + 1);
              return _context4.abrupt("break", 15);
            case 11:
              // 消息是 AI 发出的因此需要找到它的 user 消息
              userId = currentMessage.parentId;
              userIndex = chats.findIndex(function (c) {
                return c.id === userId;
              }); // 如果消息没有 parentId，那么同 user/function 模式
              contextMessages = chats.slice(0, userIndex < 0 ? currentIndex + 1 : userIndex + 1);
              return _context4.abrupt("break", 15);
            case 15:
              if (!(contextMessages.length <= 0)) {
                _context4.next = 17;
                break;
              }
              return _context4.abrupt("return");
            case 17:
              _get5 = get(), realFetchAIResponse = _get5.realFetchAIResponse;
              latestMsg = contextMessages.filter(function (s) {
                return s.role === 'user';
              }).at(-1);
              if (latestMsg) {
                _context4.next = 21;
                break;
              }
              return _context4.abrupt("return");
            case 21:
              _context4.next = 23;
              return realFetchAIResponse(contextMessages, latestMsg.id);
            case 23:
            case "end":
              return _context4.stop();
          }
        }, _callee4);
      }));
      function resendMessage(_x5) {
        return _resendMessage.apply(this, arguments);
      }
      return resendMessage;
    }(),
    sendMessage: function () {
      var _sendMessage = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5(message) {
        var _get6, dispatchMessage, realFetchAIResponse, userId, messages;
        return _regeneratorRuntime().wrap(function _callee5$(_context5) {
          while (1) switch (_context5.prev = _context5.next) {
            case 0:
              _get6 = get(), dispatchMessage = _get6.dispatchMessage, realFetchAIResponse = _get6.realFetchAIResponse;
              if (message) {
                _context5.next = 3;
                break;
              }
              return _context5.abrupt("return");
            case 3:
              userId = nanoid();
              dispatchMessage({
                id: userId,
                message: message,
                role: 'user',
                type: 'addMessage'
              });

              // Todo: need a callback before send message

              // Get the current messages to generate AI response
              messages = chatSelectors.currentChats(get());
              _context5.next = 8;
              return realFetchAIResponse(messages, userId);
            case 8:
            case "end":
              return _context5.stop();
          }
        }, _callee5);
      }));
      function sendMessage(_x6) {
        return _sendMessage.apply(this, arguments);
      }
      return sendMessage;
    }(),
    stopGenerateMessage: function stopGenerateMessage() {
      var _get7 = get(),
        abortController = _get7.abortController,
        toggleChatLoading = _get7.toggleChatLoading;
      if (!abortController) return;
      abortController.abort();
      toggleChatLoading(false);
    },
    toggleChatLoading: function toggleChatLoading(loading, id, action) {
      if (loading) {
        var _abortController = new AbortController();
        set({
          abortController: _abortController,
          chatLoadingId: id
        }, false, action);
        return _abortController;
      } else {
        set({
          abortController: undefined,
          chatLoadingId: undefined
        }, false, action);
      }
    },
    defaultModelFetcher: function defaultModelFetcher(params, options) {
      var _get8 = get(),
        request = _get8.request;
      var payload = merge(_objectSpread({
        model: initialModelConfig.model,
        stream: true
      }, initialModelConfig.params), params);
      if (typeof request === 'function') return request(payload.messages, payload);
      var url = typeof request === 'string' ? request : '/api/openai/chat';
      return fetch(url, {
        body: JSON.stringify(payload),
        headers: {
          'Content-Type': 'application/json'
        },
        method: 'POST',
        signal: options === null || options === void 0 ? void 0 : options.signal
      });
    },
    getMessageId: function () {
      var _getMessageId = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6(messages, parentId) {
        var _get9, genMessageId;
        return _regeneratorRuntime().wrap(function _callee6$(_context6) {
          while (1) switch (_context6.prev = _context6.next) {
            case 0:
              _get9 = get(), genMessageId = _get9.genMessageId;
              if (!(typeof genMessageId === 'function')) {
                _context6.next = 3;
                break;
              }
              return _context6.abrupt("return", genMessageId(messages, parentId));
            case 3:
              return _context6.abrupt("return", nanoid());
            case 4:
            case "end":
              return _context6.stop();
          }
        }, _callee6);
      }));
      function getMessageId(_x7, _x8) {
        return _getMessageId.apply(this, arguments);
      }
      return getMessageId;
    }()
  };
};